할일
*각 속성별 income과의 관계 돌리기
*!!drop_adult['sex']
*참조 dataframe drop
**https://pandas.pydata.org/docs/reference에서 찾아서 진행
adult_train['sex']
adult_test['sex']

2. Random Forest - drop 하기전
no scaler
오차 행렬
[[11601   834]
 [ 1509  2337]]
정확도: 0.8561, 정밀도: 0.7370, 재현율: 0.6076,    F1: 0.6661, AUC:0.9050
standard scaler
오차 행렬
[[11561   874]
 [ 1538  2308]]
정확도: 0.8519, 정밀도: 0.7253, 재현율: 0.6001,    F1: 0.6568, AUC:0.9019
minmax scaler
오차 행렬
[[11515   920]
 [ 1582  2264]]
정확도: 0.8463, 정밀도: 0.7111, 재현율: 0.5887,    F1: 0.6441, AUC:0.9050

1. 일단 가장 좋은 결과를 보여주는 Classifier는 Random Forest.
2. 가장 정밀도와 재현율이 일치하는 threshold의 근사값은 0.45
3. 성별 column을 drop했을 때 더 나은 결과라고 할 수 있을까요?
엄청쪼금??

이거 코드 제출 해야되지 않나요?

강사님이 아무말도 안하시네요

1시간 연장하셨대요 아마 5시까지 제출인듯 합니다.

지금 조원들 다 모여있나요?

네

근데 값 정규화 안했자나요 그것도 컬럼 하나만 한번 해볼까요?

Std랑 Min-Max 정규화 있지않나요?

그거말고 제가 말선택을 잘못했네요 이상점?아웃라이어??이거 

확실히 그 이상점 제거를 안하긴 했네요 사실 있는거 그냥 밀어 넣은 수준이죠 음음

앜ㅋㅋ저저 어제 저녁에 대충 그래프 그려봤는데 튀는값 디게많아요 그거 고쳐도 좀 아마 점수 나아질듯?

ㄱㄷㄱ 일단 제출할 거 정리해놓고 시도해봅시다. 그거 하다가 제출 못하게 되면 그것도 좀 그렇지않을까요?

넵

제출할거 정리해보겠습니다.

옙

readme 파일 이렇게 하까요?

그리고 각 팀원 무엇 했는지 지어서 적읍시다.

담당 ex) 데이터 분석, 그래프 그리기, 전처리, 결과 분석 등등

아..조장님이 혹시 정해주실수 있을까요? 죄송합니다 저희 양심상 ㅠㅠㅠ

hmmmm

일단 다들 어제 한번 해보시긴 하셨죠?

네네

1명 Feature 분석 -> 각 column 값 분석, ? 값 교체, encoding

1명 Classifier 분석 및 학습 진행 -> Decision Tree, Random Forest, Logistic Regression =>정

1명 학습 결과 분석 -> 정확도, 정밀도 재현율 F1 Score, ROC_AUC, 그래프

1명 데이터 전처리 -> drop, scaler

이 정도에서 고르면 되겠죠?
조장님 먼저 적으세요!!

감사합니다 기회되면 기프티콘 드릴게요 

기프티콘은 괜찮고 잘 배우셔서 같이 잘해봅시다.

우와 감사합니다 임한희씨가 반했대요

저는 이상값을한번 백업한다음에 정리해볼게요!

좋습니다.

조자ㅇ님 혹시 내일 오시나요?

내일 검사 결과 나오면 갈거같아요
연구원님께서 결과 나오면 오라고 하셔서요

옙

내일 오전에 한시간 더 준비시간 가지고 발표한다고 합니다

일단 지금 5시까지 하고 제출은 하고??정답을 보내주신다고 하는거 같습니다

발표는 어떤 발표인가여? 코드? 이해한거? 

코드를 이렇게 저렇게 해서 했다?이런식이 아닐까요?

오늘 코드 다 공유해가셔서 코드에 주석(#)으로 표시하셔서 이해하신거

적어보시면 좋을거 같아요.

그럼 5시에 마치는건가요? 

발표를 다시 물어봤는데 그 전처리 과정을 자세하게 말하는거라고 합니다 

어떤 자료를 빼고 넣었는지?그런 과정들?

오케이 일단 우리는 자료를 빼고 넣는거는 성별만 뺐으니

이부분은 모든 자료를 넣었을 때 어떤 결과가 나올지를 알아보면서

이 전체 학습과정을 이해하는 것에 목표를 두었다 를 밑밥을 깔고

각 column별로 value_count를 진행해서 어떤 값들이 있는지를 확인해 보았고

그 과정에서 ?가 발견된 3개의 column(workclass, occupation, native-country)가 있어서

개수를 파악 하기 위해NaN으로 replace했고 이를 하나의 값으로 하기위해 fillna를 사용해서 Unknown이라는 값으로 넣었다.

그리고 모든 데이터를 Label Encoding하여 integer값으로 바꾸고 이를 학습시켜서

Decision Tree, Random Forest, Logistic Regression에서 각 Classifier에서 어떤 Feature를 

가장 우선으로 판단하는지를 확인하였다.

이후 가장 안 쓴다고 판단된 성별을 Drop하여 테스트를 진행하였고 미약하게나마 향상되었다.

이후에는 시간이 부족해서 진행을 못했고 그래프에 따르면 다음은 인종을 drop해볼 생각이다.

이러한 일련의 과정을 시간을 들여서 진행해야 한다고 생각합니다.

정도로 말하면 될거 같은데여.

아저희 방금의견이 나왔는데

저희가 전처리한게 2개 있으니까

음

hmmmm

나머지 피쳐들도 데이터 튀는값정리하고 뭐 등등 해서 사실 내일 발표해도되니까?

그 피쳐들 각각 담당 나눠서 정리해서 오늘 내일 취합하는 걸 시도 해보는건 어떨까요

만약 실패한다면 걍 오늘꺼로 발표하고

만약 성공하면 그 업데이트한 자료로 발표합시다

어떄요?

좋은 제안이죠. 

그럼 간단하게 1나씩만??

일단 성별은 빠졌고 생각해보면 education은 education-num이라는 것이 중복되어 있으니까 이거 하나랑
native-country이건 값이 너무 많으니까 이거 하나랑
race 인종 이것도 그렇게 큰 영향은 안 끼치고
이정도는 그림에서 유추가 되는데

이제 random forest의 경우에는 나머지는 꽤 중요한 역할을 하니 빼기가 애매한거 같아요

그냥 dt이면 marital-status이걸 빼보는 것도 나쁘지 않을거 같은데

random forest에서 이걸 꽤나 중요한 판단 척도로 쓰는거 같으니 

일단 생각은 random forest가 가장 성능이 좋았으니 이걸 기준으로 잡고

추가로 native-country, race, education을 drop 해보는거 어떻습니까.

오 좋아요 그리고 사실 제가하고싶은말은 그게아니라

음 그래프 보여드릴게요 잠시만요!!

음 대충 보여주고싶었던건 80000만 이상 사람들 이상점이죠? 재내들 어케 처리를 해야할거같아서 
피쳐들마다다 이런것들있으니까 애내들도 처리해야하지않을까요

안그래도 너무 극과 극이니까 drop을 시키는 경우도 있드라구요
 
Capital gain이랑 capital loss가 아마 가장 심할거에요

이걸 z-score로 변환하는거 생각하신ㄴ건가요?

아뇨전그냥 80000이상인애들 컬럼말고 인덱스 그니까 각각의 객체를 손보려했어요!!

row 삭제..?

그건그냥 고려만...ㅎ

삭제도갠춘할..듯?아님말고요....ㅎ

저 데이터들 특징이 0이 너무 많아서 변별력이 없는거 아닌가 라는 생각이 들 정도긴 하니깐요

음...드랍하고 결과보고 너무 안좋아지면 다시 넣을까요?

그것도 시간이 되면 해보면 좋죠

그럼 그냥이것만할까요?

잠시만요 capital gain이 생각보다 중요도가 높네요

일단 그럼 capital gain이랑 loss이거 따로 드랍해보고 결과 나쁘면 되돌리는 걸로 어떤가요

오 좋아요!!

아직 시간이 남아서 일단 이자리에서 해볼게요!!

** 1차
1. race
2. native-country
3. education
=> 우선 결과 보고
** 2차
4. capital gain
5. capital loss
=> 각 결과 보고 조합.

으로 진행해봅시다.

넵 일단 해볼게요!!

백업할게요!!